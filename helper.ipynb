{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_imgs = np.load('train_images.npy')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "test_imgs = np.load('test_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = np.unique(train_labels)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for category in unique_categories:\n",
    "    indices = np.where(train_labels == category)[0]\n",
    "    category_images = train_imgs[indices]\n",
    "    datasets[category] = category_images\n",
    "\n",
    "print(datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms():\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(10, 12))\n",
    "\n",
    "    keys = {\n",
    "    0:    'T-shirt/top',\n",
    "    1:    'Trouser',\n",
    "    2:    'Pullover',\n",
    "    3:    'Dress',\n",
    "    4:    'Coat',\n",
    "    5:    'Sandal',\n",
    "    6:    'Shirt',\n",
    "    7:    'Sneaker',\n",
    "    8:    'Bag',\n",
    "    9:    'Ankle boot'}\n",
    "\n",
    "    for ind, ax in enumerate(axes.flatten()):\n",
    "        counts, bins = np.histogram(datasets[ind].flatten())\n",
    "        ax.stairs(counts/datasets[ind].flatten().size, bins)\n",
    "        ax.set_ylim([0,.8])\n",
    "        ax.set_title(str(keys[ind]))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_items():\n",
    "    fig, axes = plt.subplots(2, 5)\n",
    "\n",
    "    for ind, ax in enumerate(axes.flatten()):\n",
    "\n",
    "        ax.imshow(np.average(datasets[ind], axis=0))\n",
    "        ax.set_title(str(keys[ind]))\n",
    "\n",
    "    fig.suptitle('Figuras promedio de las clases')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_softmax_model(output_size = 10):\n",
    "    \n",
    "    normal_initializer = keras.initializers.GlorotNormal\n",
    "    uniform_initializer = keras.initializers.GlorotUniform\n",
    "    K.clear_session()\n",
    "    softmax_model = Sequential()\n",
    "    softmax_model.add(Flatten(input_shape=(28,28)))\n",
    "    softmax_model.add(BatchNormalization())\n",
    "    softmax_model.add(Dense(output_size, activation='softmax',  kernel_initializer=uniform_initializer, name='salida'))\n",
    "    softmax_model.summary()\n",
    "\n",
    "    import time\n",
    "    adam = optimizers.Adam(learning_rate=0.001, decay=1E-4) #decay=1e-4\n",
    "    checkpointer = ModelCheckpoint(filepath='softmax.mnist.hdf5', verbose=1, save_best_only=True, mode='max', monitor='val_accuracy')\n",
    "\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    softmax_model.compile(loss = 'categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    softmax_model.fit(X_train, \n",
    "            y_train_categorical ,\n",
    "            epochs=100, batch_size=2048, \n",
    "            verbose=0, \n",
    "            validation_data=(X_val, y_val_categorical), \n",
    "            callbacks=[earlyStopping],\n",
    "            )\n",
    "    return softmax_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train_categorical, X_val, y_val_categorical, opt, b_s, act, pat, init):\n",
    "\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0,\n",
    "        patience=pat,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=False,\n",
    "    )\n",
    "\n",
    "    output_size = 10\n",
    "\n",
    "    K.clear_session()\n",
    "    model_mpl = Sequential()\n",
    "    model_mpl.add(Flatten(input_shape=(28,28)))\n",
    "    model_mpl.add(BatchNormalization())\n",
    "    model_mpl.add(Dense(500, activation=act, kernel_initializer=init, name='middle1'))\n",
    "    model_mpl.add(BatchNormalization())\n",
    "    model_mpl.add(Dense(200, activation=act, kernel_initializer=init, name='middle2'))\n",
    "    model_mpl.add(Dense(output_size, activation='softmax',  kernel_initializer=init, name='salida'))\n",
    "    model_mpl.compile(loss = 'categorical_crossentropy', optimizer=opt , metrics=['accuracy'])\n",
    "\n",
    "    #sys.stdout = open(os.devnull, 'w')\n",
    "    history = model_mpl.fit(X_train, \n",
    "        y_train_categorical ,\n",
    "        epochs=100, batch_size=b_s, \n",
    "        verbose=0, \n",
    "        validation_data=(X_val, y_val_categorical), \n",
    "        callbacks=[earlyStopping],\n",
    "        )\n",
    "\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "    return val_acc, model_mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_size_graphs():\n",
    "    plt.xlabel(\"batch size\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title(\"Validation accuracy vs Batch Size\")\n",
    "    plt.plot(batch_sizes, [x[-1] for x in accuracy_values])\n",
    "    plt.show()\n",
    "    plt.xlabel(\"batch size\")\n",
    "    plt.ylabel(\"number of iterations\")\n",
    "    plt.title(\"Numer of Iterations vs Batch Size\")\n",
    "    plt.plot(batch_sizes, [len(x) for x in accuracy_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_learning_rate_graphs():\n",
    "    plt.xlabel(\"learning rate\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.xscale('log')\n",
    "    plt.title('Val Accuracy vs Learning rate for SGD optimizer')\n",
    "    plt.plot(learning_rates, [x[-1] for x in accuracy_values])\n",
    "    plt.show()\n",
    "\n",
    "    plt.xlabel(\"learning rate\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.xscale('log')\n",
    "    plt.title('Numer of Iterations vs Learning rate for SGD optimizer')\n",
    "    plt.plot(learning_rates, [len(x) for x in accuracy_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer_graphs():\n",
    "    plt.bar(['SGD', 'adam', 'adamax', 'nadam'], [x[-1] for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "    plt.xlabel(\"optimizer\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Validation Accuracy vs Optimizer')\n",
    "    plt.ylim(0.8, 0.9)\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(['SGD', 'adam', 'adamax', 'nadam'], [len(x) for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "\n",
    "    plt.xlabel(\"optimizer\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Numer of Iterations vs Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_activation_graphs():\n",
    "    # Create the bar plot\n",
    "    # creating the bar plot\n",
    "    plt.bar(activations, [x[-1] for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"activation\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Validation Accuracy vs Activation Function')\n",
    "\n",
    "    # Display the plot\n",
    "\n",
    "    # Display the plot\n",
    "    plt.ylim(0.8, 0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Create the bar plot\n",
    "    # creating the bar plot\n",
    "    plt.bar(activations, [len(x) for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"activation\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Number of Iterations vs Activation Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_initializer_graphs():\n",
    "    # Create the bar plot\n",
    "    # creating the bar plot\n",
    "    plt.bar(['N sigma .1', 'N sigma 1', 'N Glorot', 'U Glorot'], [x[-1] for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Kernel Initialization\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Validation Accuracy vs Initialization')\n",
    "\n",
    "    # Display the plot\n",
    "\n",
    "    # Display the plot\n",
    "    plt.ylim(0.84, 0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Create the bar plot\n",
    "    # creating the bar plot\n",
    "    plt.bar(['N sigma .1', 'N sigma 1', 'N Glorot', 'U Glorot'], [len(x) for x in accuracy_values], color ='maroon',\n",
    "            width = 0.4)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Kernel Initialization\")\n",
    "    plt.ylabel(\"validation accuracy\")\n",
    "    plt.title('Number of Iterations vs Initialization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
